WEBVTT
Kind: captions
Language: zh-Hans

00:00:12.290 --> 00:00:17.880
让我们来谈谈我们很多人遭受的直觉失败的真正原因

00:00:17.880 --> 00:00:22.710
未能检测到某种危险，我要描述一种情况

00:00:22.710 --> 00:00:29.460
我认为这既可怕又可能发生，这不是一个好选择

00:00:29.460 --> 00:00:34.170
事实证明这是一种结合，但你们大多数人都不会害怕

00:00:34.170 --> 00:00:36.510
觉得我在说的很酷

00:00:36.510 --> 00:00:42.239
我要描述一下我们在人工智能中获得的收益

00:00:42.239 --> 00:00:45.360
最终摧毁了我们，事实上，我认为很难看到它们如何

00:00:45.360 --> 00:00:49.890
不会摧毁我们或激发我们摧毁我们自己，但是如果你是

00:00:49.890 --> 00:00:54.420
像我这样的人，您会发现思考这些事情很有趣，

00:00:54.420 --> 00:01:00.210
回应是问题的一部分，好吧，如果我愿意，回应会让您担心

00:01:00.210 --> 00:01:05.369
在这次谈话中说服您我们可能会遭受全球饥荒

00:01:05.369 --> 00:01:09.630
由于气候变化或其他灾难而造成的

00:01:09.630 --> 00:01:14.390
孙子或孙子很可能这样生活

00:01:14.390 --> 00:01:20.869
你不会觉得有趣我喜欢这个TED演讲

00:01:20.869 --> 00:01:27.570
饥荒不是有趣的事情，另一方面，科幻小说中的死亡是有趣的，

00:01:27.570 --> 00:01:30.689
在这一点上，最让我担心的是AI的发展

00:01:30.689 --> 00:01:35.579
我们似乎无法调动对

00:01:35.579 --> 00:01:39.720
前方的危险我无法封送这个回应，而我给

00:01:39.720 --> 00:01:46.649
就像我们站在一号门后面的两扇门前

00:01:46.649 --> 00:01:50.460
在建设智能机器方面取得进展，我们的计算机硬件和

00:01:50.460 --> 00:01:54.540
出于某种原因，软件只是停止变得更好，现在花点时间

00:01:54.540 --> 00:01:59.759
考虑为什么会发生这种情况，但是考虑到智能和自动化的价值

00:01:59.759 --> 00:02:05.520
如果我们有能力做到什么，我们将继续改进我们的技术吗？

00:02:05.520 --> 00:02:13.310
可能阻止我们进行一场全面的核战争，成为全球性的大流行病

00:02:13.310 --> 00:02:24.959
小行星撞击贾斯汀·比伯（Justin Bieber）成为美国总统

00:02:24.959 --> 00:02:30.360
关键是必须摧毁文明，因为我们知道嘿

00:02:30.360 --> 00:02:35.670
想像一下阻止我们进行改进将有多糟糕

00:02:35.670 --> 00:02:40.739
在我们的技术中永久地世代相传

00:02:40.739 --> 00:02:44.730
定义这是人类历史上最糟糕的事情，所以

00:02:44.730 --> 00:02:48.630
唯一的选择，而这是第二扇门的背后是

00:02:48.630 --> 00:02:53.160
年复一年地继续改善我们的智能机器，并且

00:02:53.160 --> 00:02:57.209
在某一点上，我们将制造比我们更智能的机器

00:02:57.209 --> 00:03:00.660
一旦我们拥有比我们更智能的机器，它们就会开始

00:03:00.660 --> 00:03:05.700
改善自己，然后冒险与数学家AI J

00:03:05.700 --> 00:03:10.739
现在该过程可能会远离我们的情报爆炸

00:03:10.739 --> 00:03:16.440
像我在这里一样讽刺漫画，是因为担心大量的恶意机器人会

00:03:16.440 --> 00:03:21.420
攻击我们，但这不是最可能的情况，不是我们的机器

00:03:21.420 --> 00:03:27.150
会自发地恶毒，因为我们担心的是

00:03:27.150 --> 00:03:30.540
制造比我们能力强得多的机器

00:03:30.540 --> 00:03:36.420
他们自己目标之间的分歧可能会摧毁我们，只是想一想

00:03:36.420 --> 00:03:41.819
我们如何与蚂蚁相处好吧，我们不恨他们，我们不会竭尽全力伤害他们

00:03:41.819 --> 00:03:45.329
实际上，有时候我们会竭尽全力不伤害他们，只是我们越过它们

00:03:45.329 --> 00:03:48.680
在人行道上，但只要他们在场

00:03:48.680 --> 00:03:52.590
与我们的目标之一严重冲突

00:03:52.590 --> 00:03:57.720
像这样的建筑物，我们毫不犹豫地消灭了他们，担心的是

00:03:57.720 --> 00:04:02.430
我们将有一天建造一台机器，无论他们是否有意识

00:04:02.430 --> 00:04:07.920
现在我以同样的无视对待我们，我怀疑这似乎对许多人来说牵强

00:04:07.920 --> 00:04:14.150
我敢打赌他们是那些怀疑超级智能AI是否会影响你们的人

00:04:14.150 --> 00:04:17.940
可能少了一些不可避免的权利，但后来你

00:04:17.940 --> 00:04:21.359
必须通过以下假设之一找到问题，并且它们是

00:04:21.359 --> 00:04:25.910
他们中只有三个是智力的问题

00:04:25.910 --> 00:04:30.290
物理系统中的信息处理好了，实际上这有点

00:04:30.290 --> 00:04:34.670
不仅仅是一个假设，但我们已经将狭义的情报纳入其中

00:04:34.670 --> 00:04:39.200
我们的机器以及其中许多机器的性能都达到了超人的水平

00:04:39.200 --> 00:04:44.510
情报已经存在，我们知道光是物质就能引起什么

00:04:44.510 --> 00:04:48.440
被称为一般智力，具有跨多个领域灵活思考的能力

00:04:48.440 --> 00:04:56.000
领域，因为我们的大脑已经正确处理了，也许其中只有原子

00:04:56.000 --> 00:05:02.420
只要我们继续建立更多显示原子的原子系统

00:05:02.420 --> 00:05:06.890
除非我们被打扰，否则我们最终将采取更明智的行为

00:05:06.890 --> 00:05:11.570
最终将在我们的机器中建立通用情报

00:05:11.570 --> 00:05:16.580
至关重要的是要认识到进展的速度与进展是否重要无关

00:05:16.580 --> 00:05:20.060
足以使我们进入最终区域，我们不需要摩尔定律就可以继续

00:05:20.060 --> 00:05:25.970
不，我们不需要指数级的进步，我们只需要继续第二

00:05:25.970 --> 00:05:31.160
假设我们将继续前进，我们将继续提高我们的智慧

00:05:31.160 --> 00:05:37.040
机器并赋予智能价值

00:05:37.040 --> 00:05:41.480
你知道，情报要么是我们重视的一切的源头，要么是我们需要的

00:05:41.480 --> 00:05:46.910
它可以保护我们珍视的一切，这是我们最宝贵的资源，因此我们希望

00:05:46.910 --> 00:05:51.410
为此，我们迫切需要解决一些我们想要解决的问题

00:05:51.410 --> 00:05:56.300
治疗您想了解经济的疾病，例如老年痴呆症和癌症

00:05:56.300 --> 00:06:01.370
我们想要改善气候科学的系统，所以如果可以的话，我们将做到这一点

00:06:01.370 --> 00:06:07.190
火车已经出站了，没有刹车了，我们终于可以拉了

00:06:07.190 --> 00:06:14.180
不要站在情报高峰或接近情报高峰的地方，这确实

00:06:14.180 --> 00:06:17.510
至关重要的见解，这就是使我们的处境如此and可危，

00:06:17.510 --> 00:06:23.540
这就是使我们对风险的直觉如此不可靠的原因

00:06:23.540 --> 00:06:28.040
考虑一下有史以来最聪明的人，几乎每个人都入围

00:06:28.040 --> 00:06:32.390
这是约翰·冯·诺依曼（John von Neumann），也许是有趣的女人在

00:06:32.390 --> 00:06:34.660
他周围的人，其中包括最伟大的

00:06:34.660 --> 00:06:39.380
他那个时代的数学家和物理学家都有据可查

00:06:39.380 --> 00:06:44.600
如果关于他的故事只有一半是真的，那毫无疑问他就是其中之一

00:06:44.600 --> 00:06:49.540
有史以来最聪明的人，因此请考虑智力的范围

00:06:49.540 --> 00:06:56.660
在这里，我们有约翰·冯·诺伊曼（John von Neumann），然后我们有您和我，然后我们有一个

00:06:56.660 --> 00:07:03.980
对不起，对不起，我没有理由让这个话题更加令人沮丧

00:07:03.980 --> 00:07:11.360
需要的是，然而，

00:07:11.360 --> 00:07:16.520
情报的扩展范围超出了我们目前的构想，如果我们建立

00:07:16.520 --> 00:07:20.600
比我们更智能的机器，他们很可能会探索

00:07:20.600 --> 00:07:25.040
我们无法想象和超越我们的方式

00:07:25.040 --> 00:07:29.540
无法想象，重要的是要认识到这是真的

00:07:29.540 --> 00:07:34.700
速度快吧，所以想象我们刚刚建造了一个超级

00:07:34.700 --> 00:07:40.100
智慧的AI权利，并不比您的一般研究人员团队聪明

00:07:40.100 --> 00:07:44.750
斯坦福大学或麻省理工学院的电子电路运行速度提高约一百万倍

00:07:44.750 --> 00:07:49.190
比生化的好，所以这台机器应该考虑一百万

00:07:49.190 --> 00:07:52.850
比人们想象的速度快了十倍，所以你说它运行了一个星期，

00:07:52.850 --> 00:07:59.480
它将每周执行20,000年的人类智力工作

00:07:59.480 --> 00:08:06.140
一周后，我们怎么能甚至不那么了解这种想法的局限性

00:08:06.140 --> 00:08:13.570
那种进步坦白说，令人担忧的另一件事是

00:08:13.570 --> 00:08:18.710
想像一下最佳情况，想像一下我们遇到了超级设计

00:08:18.710 --> 00:08:23.480
无需担心安全性的智能AI，我们拥有完美的设计

00:08:23.480 --> 00:08:27.560
第一次，好像我们被交给了一个行为举止的神谕

00:08:27.560 --> 00:08:32.860
完全符合预期，这台机器将是理想的省力设备

00:08:32.860 --> 00:08:37.130
它可以设计可以建造可以做任何物理动作的机器的机器

00:08:37.130 --> 00:08:42.260
由阳光驱动的工作或多或少地需要原材料成本，所以

00:08:42.260 --> 00:08:46.250
我们在谈论人类苦役的终结，我们也在谈论

00:08:46.250 --> 00:08:51.170
大部分智力工作的结束，所以像我们这样的作品会在这方面做些什么

00:08:51.170 --> 00:08:54.970
我们的立场很好，我们可以自由玩飞盘

00:08:54.970 --> 00:09:00.100
并互相按摩，增加一些LSD和一些可疑的衣柜

00:09:00.100 --> 00:09:07.690
选择和整个世界现在可能像《燃烧的人》，听起来像

00:09:07.690 --> 00:09:13.120
很好，但请问自己，在当前的经济形势下会发生什么

00:09:13.120 --> 00:09:17.710
政治秩序似乎我们会见证一定程度的财富

00:09:17.710 --> 00:09:23.080
在没有意愿的情况下我们从未见过的不平等和失业

00:09:23.080 --> 00:09:28.030
马上把这些新财富带给全人类，好吧

00:09:28.030 --> 00:09:31.420
几万亿个领域可以提高我们商业杂志的封面，而

00:09:31.420 --> 00:09:35.380
世界其他地方都可以自由挨饿，而俄国人或

00:09:35.380 --> 00:09:39.970
如果中国人听说硅谷的某家公司即将

00:09:39.970 --> 00:09:43.840
部署超级智能AI，这台机器将能够发动战争

00:09:43.840 --> 00:09:50.680
对，无论是靠空前的力量休息铁路还是网络，这都是

00:09:50.680 --> 00:09:54.730
优胜者通吃情景在比赛之前六个月就完成了

00:09:54.730 --> 00:10:01.000
至少要提前五十万年，所以即使

00:10:01.000 --> 00:10:05.820
仅仅有这种突破的谣言就可能使我们的物种发疯

00:10:05.820 --> 00:10:12.610
现在，在我看来，目前最恐怖的事情之一是

00:10:12.610 --> 00:10:19.540
AI研究人员想要放心时会说些什么，以及

00:10:19.540 --> 00:10:23.410
告诉我们不要担心的最常见原因是时间，这还有很长的路要走

00:10:23.410 --> 00:10:28.030
你不知道这可能是五十或一百年了吗

00:10:28.030 --> 00:10:31.330
研究人员表示，担心AI安全就像担心

00:10:31.330 --> 00:10:36.400
火星上人口过多这是硅谷版本的不用担心

00:10:36.400 --> 00:10:43.190
关于它的漂亮的小脑袋，似乎没有人注意到

00:10:43.190 --> 00:10:48.320
如果智力只是一个问题，那么时间范围是完全不存在的。

00:10:48.320 --> 00:10:53.510
信息处理，我们将继续改进我们将生产的机器

00:10:53.510 --> 00:11:00.170
某种形式的超级智能，我们不知道要花多长时间

00:11:00.170 --> 00:11:06.850
为安全地创造条件创造条件让我再说一次，我们不知道

00:11:06.850 --> 00:11:13.220
如果您愿意，我们将花多长时间来创造条件以安全地做到这一点

00:11:13.220 --> 00:11:17.480
还没有注意到50年不再是过去了，这是50年

00:11:17.480 --> 00:11:20.650
几个月，这就是我们使用iPhone多长时间了

00:11:20.650 --> 00:11:25.790
这是辛普森一家在电视上已经有五十年的历史了，不是吗？

00:11:25.790 --> 00:11:30.820
很多时间来应对我们物种面临的最大挑战之一

00:11:30.820 --> 00:11:34.850
再一次，我们似乎没有适当的情感回应

00:11:34.850 --> 00:11:40.250
我们有充分的理由相信即将到来。计算机科学家

00:11:40.250 --> 00:11:44.120
斯图尔特·罗素（Stuart Russell）在这里有一个很好的类比，他说想像我们收到了

00:11:44.120 --> 00:11:51.200
来自外星文明的信息，它读到了地球上的人们，我们将到达

00:11:51.200 --> 00:11:57.260
您的星球在50年后就准备好了，现在我们只在数数个月

00:11:57.260 --> 00:12:04.000
直到母权获得通过，我们会比我们更加紧迫

00:12:04.000 --> 00:12:08.839
有人告诉我们不要担心的另一个原因是，这些机器无济于事

00:12:08.839 --> 00:12:11.720
分享我们的价值观，因为它们实际上是我们自身的延伸

00:12:11.720 --> 00:12:15.320
他们将被移植到我们的大脑上，并将基本上成为他们的边缘

00:12:15.320 --> 00:12:20.570
系统花一点时间考虑最安全，唯一谨慎的方法

00:12:20.570 --> 00:12:26.810
向前推荐的方法是现在将这项技术直接植入我们的大脑

00:12:26.810 --> 00:12:30.080
该垫子实际上可能是最安全，唯一谨慎的前进方向，但

00:12:30.080 --> 00:12:34.190
通常，必须对一项技术的安全性进行充分的研究

00:12:34.190 --> 00:12:41.390
在把它粘在脑海里之前，更深层的问题是建筑物

00:12:41.390 --> 00:12:46.820
超级人工智能本身似乎比构建超级人工智能更容易

00:12:46.820 --> 00:12:50.209
智能AI并拥有完整的神经科学，使我们能够

00:12:50.209 --> 00:12:54.360
无缝整合我们的思想，并考虑到公司和

00:12:54.360 --> 00:12:57.810
从事这项工作的政府可能会认为自己处于竞争状态

00:12:57.810 --> 00:13:03.300
反对所有其他人，因为赢得这场比赛就是为了赢得世界，

00:13:03.300 --> 00:13:07.110
您不会在下一刻将其销毁，那么无论

00:13:07.110 --> 00:13:12.029
不幸的是，首先要做的事情很容易完成，但是我对此有解决方案

00:13:12.029 --> 00:13:16.230
问题或建议我们更多地考虑一下，我认为我们需要

00:13:16.230 --> 00:13:20.730
类似于关于人工智能的曼哈顿计划之类的东西，

00:13:20.730 --> 00:13:24.750
之所以建立它，是因为我认为我们将不可避免地这样做，但要了解如何

00:13:24.750 --> 00:13:29.370
避免军备竞赛并以符合我们利益的方式进行

00:13:29.370 --> 00:13:33.060
当您谈论可以对以下方面进行更改的超级智能AI时

00:13:33.060 --> 00:13:38.100
本身，看来我们只有一次机会获得最初的

00:13:38.100 --> 00:13:42.240
条件正确，即使如此，我们仍需要吸收经济和

00:13:42.240 --> 00:13:47.510
使他们正确的政治后果，但我们承认这一刻

00:13:47.510 --> 00:13:53.550
信息处理是一些适当的情报来源

00:13:53.550 --> 00:13:59.160
计算系统是智能的基础，我们承认我们

00:13:59.160 --> 00:14:04.830
将持续改善这些系统，我们承认

00:14:04.830 --> 00:14:11.070
认知很可能远远超过我们目前所知道的，那么我们必须承认

00:14:11.070 --> 00:14:16.320
我们正在建立某种神的过程中，这将是一个很好的选择

00:14:16.320 --> 00:14:21.110
是时候确定这是我们可以与之相处的神了，非常感谢

00:14:21.110 --> 00:14:27.299
[掌声]

